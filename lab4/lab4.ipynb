{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return f.read().replace('\\n', ' ')\n",
    "\n",
    "articles_list = []\n",
    "articles_name = []\n",
    "\n",
    "path = \"ustawy\"\n",
    "for file in os.listdir(path):\n",
    "    # Check whether file is in text format or not\n",
    "    file_path = f\"{path}/{file}\"\n",
    "    temp = read_text_file(file_path).replace('\\n',' ')\n",
    "    temp = temp.replace('\\xa0', ' ')\n",
    "    temp = re.sub('\\s+',' ', temp)\n",
    "    articles_list.append(temp.replace('\\xa0', ' '))\n",
    "    articles_name.append(file)\n",
    "\n",
    "import re\n",
    "\n",
    "articles_list = [re.sub('<[^<]+?>', '', text) for text in articles_list]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Use SpaCy tokenizer API to tokenize the text from the law corpus."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "from spacy.lang.pl import Polish\n",
    "#from spacy.tokenizer import Tokenizer\n",
    "nlp = Polish()\n",
    "tokenizer = nlp.tokenizer\n",
    "#tokenizer = Tokenizer(nlp.vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "doc = [tokenizer(art) for art in articles_list]\n",
    "doc_text = [[token.text for token in document if token.text != \" \"] for document in doc]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Compute bigram counts of downcased tokens. Given the sentence: \"The quick brown fox jumps over the lazy dog.\", the bigram counts are as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wyznaczemy najpierw bigramy uwzględniajac kropki oraz inne znaki jak w przykładzie. Nastepnie zliczane sa ilosci wystapien"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "bigrams = [[f'{doc[i].lower()} {doc[i+1].lower()}' for i in range(len(doc)) if i != len(doc)-1] #laczenie w pary\n",
    "           for doc in doc_text]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "['dz .', '. u', 'u .', '. z', 'z 1996']"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[1][:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "frequency_bigram_list = [Counter(big) for big in bigrams]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "global_frequency_bigram = sum(frequency_bigram_list, Counter())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "[('art .', 83778),\n ('ust .', 53552),\n ('poz .', 45198),\n (', poz', 43188),\n ('. 1', 39953)]"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_frequency_bigram.most_common(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Discard bigrams containing characters other than letters. Make sure that you discard the invalid entries after computing the bigram counts."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "sprawdzenie czy bigram zawiera tylko litery poprzez isalpha()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "for e in list(global_frequency_bigram):\n",
    "    temp = e.replace(\" \", \"\")\n",
    "    if not temp.isalpha():\n",
    "        del global_frequency_bigram[e]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "[('w art', 32042),\n ('mowa w', 28471),\n ('w ust', 23557),\n ('o których', 13884),\n ('których mowa', 13857)]"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_frequency_bigram.most_common(5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Use pointwise mutual information to compute the measure for all pairs of words.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funkcja Pmi wyznacza pomiary w bigramie"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "[('w', 201224), ('i', 90009), ('art', 83804), ('z', 82443), ('o', 64776)]"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_words_only = [[token.text.lower() for token in document if token.is_alpha and token.text != \" \"] for document in doc]\n",
    "frequency_list_words = [Counter(doc) for doc in doc_words_only]\n",
    "global_frequency_list_words = sum(frequency_list_words, Counter())\n",
    "global_frequency_list_words.most_common(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "\n",
    "total = sum(global_frequency_list_words.values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "from numpy import log\n",
    "def pmi(bi, total, global_frequency_list_words):\n",
    "    w1, w2 = bi[0].split(\" \")\n",
    "    val_bi =bi[1]\n",
    "    val_w1 = global_frequency_list_words.__getitem__(w1)\n",
    "    vaw_w2 = global_frequency_list_words.__getitem__(w2)\n",
    "    if ((val_w1/total)*(vaw_w2/total)) == 0:\n",
    "        print(f'{w1}: {val_w1}, {w2}: {vaw_w2}')\n",
    "    return (w1, w2, log((val_bi/total)/((val_w1/total)*(vaw_w2/total))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "('mowa', 'w', 2.867627254917188)"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi(global_frequency_bigram.most_common(5)[1], total, global_frequency_list_words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "pmi_tab = [pmi(bi, total, global_frequency_list_words) for bi in global_frequency_bigram.most_common()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "[('w', 'art', 1.9170929678118054),\n ('mowa', 'w', 2.867627254917188),\n ('w', 'ust', 2.0557286964261223),\n ('o', 'których', 3.7561599873615954),\n ('których', 'mowa', 4.5653636387808385)]"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi_tab[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5.Sort the word pairs according to that measure in the descending order and determine top 10 entries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "pmi_tab.sort(key=lambda x: x[2], reverse= True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "[('acetanilid', 'acetylometadol', 15.090700159021198),\n ('admi', 'nistracji', 15.090700159021198),\n ('adminis', 'tracji', 15.090700159021198),\n ('aegroti', 'suprema', 15.090700159021198),\n ('aerodynamicznej', 'szorstkości', 15.090700159021198),\n ('aethina', 'tumida', 15.090700159021198),\n ('agenci', 'ubezpieczeniowi', 15.090700159021198),\n ('agregatach', 'pralniczych', 15.090700159021198),\n ('agricoltura', 'biologica', 15.090700159021198),\n ('agriculture', 'biologique', 15.090700159021198)]"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi_tab[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Filter bigrams with number of occurrences <strong>higher</strong> than 5. Determine top 10 entries for the remaining dataset (>=5 occurrences)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "pmi_tab_filtered = [pmi(bi, total, global_frequency_list_words) for bi in global_frequency_bigram.most_common() if bi[1] > 5]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "[('adama', 'mickiewicza', 13.298940689793143),\n ('odczynów', 'poszczepiennych', 13.298940689793143),\n ('diagności', 'laboratoryjni', 13.298940689793143),\n ('słomę', 'makową', 13.298940689793143),\n ('lambrekiny', 'okienne', 13.144790009965886),\n ('zatoki', 'gdańskiej', 13.144790009965886),\n ('poddanymi', 'aromatyzacji', 13.144790009965886),\n ('piotrków', 'trybunalski', 13.144790009965885),\n ('zapieczętowanej', 'kopercie', 13.144790009965885),\n ('papierem', 'wartościowym', 13.144790009965885)]"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi_tab_filtered.sort(key=lambda x: x[2], reverse= True)\n",
    "pmi_tab_filtered[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7. Use KRNNT or Clarin-PL API(https://ws.clarin-pl.eu/tager.shtml) to tag and lemmatize the corpus."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jest uzyte Clarin-PL, nastepnie regex zeby wyciagnac z dok. odpowiednie slowo oraz oznaczenie"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "regex_pattern = '\\<base\\>(\\w+)\\<\\/base\\>\\<ctag\\>(\\w+)'\n",
    "words_7 = []\n",
    "path = \"ustawy_lab4\"\n",
    "for file in os.listdir(path):\n",
    "    # Check whether file is in text format or not\n",
    "    file_path = f\"{path}/{file}\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        text =  f.read()\n",
    "        res = re.findall(r\"\\<base\\>(\\w+)\\<\\/base\\>\\<ctag\\>(\\w+)\", text)\n",
    "        words_7.append(res)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "8. Using the tagged corpus compute bigram statistic for the tokens containing: a. lemmatized, downcased word b. morphosyntactic category of the word (subst, fin, adj, etc.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "bigrams_7 = [[f'{doc[i][0].lower()}:{doc[i][1]} {doc[i+1][0].lower()}:{doc[i+1][1].lower()}' for i in range(len(doc)) if i != len(doc)-1] #laczenie w pary\n",
    "            for doc in words_7]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "9. For example: \"Ala ma kota\", which is tagged as:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Przykładowo wyciągnięte bigramy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "['u:prep z:prep',\n 'z:prep 2001:num',\n '2001:num r:ign',\n 'r:ign nr:subst',\n 'nr:subst 63:num',\n '63:num poz:ign',\n 'poz:ign 639:num',\n '639:num ustawa:subst',\n 'ustawa:subst z:prep',\n 'z:prep dzień:subst']"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_7[15][:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "10. Compute the same statistics as for the non-lemmatized words (i.e. PMI) and print top-10 entries with at least 5 occurrences."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "[('w:prep art:ign', 32045),\n ('o:prep który:adj', 28656),\n ('który:adj mowa:subst', 28538),\n ('mowa:subst w:prep', 28473),\n ('w:prep usta:subst', 23557)]"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_bigram_7_list = [Counter(big) for big in bigrams_7]\n",
    "global_frequency_bigram_7 = sum(frequency_bigram_7_list, Counter())\n",
    "global_frequency_bigram_7.most_common(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "[('w:prep', 202951),\n ('i:conj', 90044),\n ('z:prep', 87991),\n ('art:ign', 83805),\n ('1:num', 74573)]"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_words_only_7 = [[f'{document[i][0].lower()}:{document[i][1]}' for i in range(len(document)) if document[i] != \" \"] for document in words_7]\n",
    "frequency_list_words_7 = [Counter(doc) for doc in doc_words_only_7]\n",
    "global_frequency_list_words_7 = sum(frequency_list_words_7, Counter())\n",
    "global_frequency_list_words_7.most_common(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "total_7 = sum(global_frequency_list_words_7.values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "pmi_tab_filtered_7 = [pmi(bi, total_7, global_frequency_list_words_7) for bi in global_frequency_bigram_7.most_common() if bi[1]> 5]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "[('w:prep', 'art:ign', 2.060368419895352),\n ('o:prep', 'który:adj', 3.619016874504095),\n ('który:adj', 'mowa:subst', 4.425786061112725),\n ('mowa:subst', 'w:prep', 3.010127213150502),\n ('w:prep', 'usta:subst', 2.198829241685272)]"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi_tab_filtered_7[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "[('postępować:fin', 'postępywać:fin', 13.450680306867234),\n ('ląg:subst', 'lęg:subst', 13.450680306867234),\n ('adam:subst', 'mickiewicz:subst', 13.450680306867234),\n ('obrząd:subst', 'obrzęd:subst', 13.450680306867234),\n ('pielić:fin', 'pleć:fin', 13.450680306867234),\n ('warmińsko:adv', 'mazurski:adj', 13.296529627039975),\n ('ciesać:pact', 'cieszyć:pact', 13.296529627039975),\n ('piotrek:subst', 'trybunalski:adj', 13.296529627039975),\n ('media:subst', 'medium:subst', 13.296529627039975),\n ('teologiczno:ign', 'pastoralny:adj', 13.296529627039975)]"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi_tab_filtered_7.sort(key=lambda x: x[2], reverse=True)\n",
    "pmi_tab_filtered_7[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "11. Compute trigram counts for both corpora and perform the same filtering."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "trigrams = [[f'{doc[i].lower()} {doc[i+1].lower()} {doc[i+2].lower()}' for i in range(len(doc)) if i < len(doc)-2] #laczenie w pary\n",
    "           for doc in doc_text]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "frequency_trigram_list = [Counter(big) for big in trigrams]\n",
    "global_frequency_trigram = sum(frequency_trigram_list, Counter())\n",
    "global_frequency_trigram.most_common(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "[('o których mowa', 13856),\n ('których mowa w', 13806),\n ('mowa w ust', 13474),\n ('mowa w art', 12311),\n ('o którym mowa', 9169)]"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for e in list(global_frequency_trigram):\n",
    "    temp = e.replace(\" \", \"\")\n",
    "    if not temp.isalpha() or global_frequency_trigram[e] <= 5:\n",
    "        del global_frequency_trigram[e]\n",
    "global_frequency_trigram.most_common(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "[('o:prep który:adj mowa:subst', 28535),\n ('który:adj mowa:subst w:prep', 28442),\n ('_:interp _:interp _:interp', 16213),\n ('mowa:subst w:prep usta:subst', 13474),\n ('w:prep usta:subst 1:num', 12842)]"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_7 = [[f'{doc[i][0].lower()}:{doc[i][1]} {doc[i+1][0].lower()}:{doc[i+1][1].lower()} {doc[i+2][0].lower()}:{doc[i+2][1].lower()}' for i in range(len(doc)) if i < len(doc)-2] #laczenie w pary\n",
    "            for doc in words_7]\n",
    "frequency_trigram_7_list = [Counter(big) for big in trigrams_7]\n",
    "global_frequency_trigram_7 = sum(frequency_trigram_7_list, Counter())\n",
    "global_frequency_trigram_7.most_common(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "[('o:prep który:adj mowa:subst', 28535),\n ('który:adj mowa:subst w:prep', 28442),\n ('mowa:subst w:prep usta:subst', 13474),\n ('mowa:subst w:prep art:ign', 12311),\n ('dwa:num dwa:num dwa:num', 8732)]"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for e in list(global_frequency_trigram_7):\n",
    "    temp = e.replace(\" \", \"\")\n",
    "    temp = temp.replace(\":\", \"\")\n",
    "    if not temp.isalpha() or global_frequency_trigram_7[e] <= 5:\n",
    "        del global_frequency_trigram_7[e]\n",
    "global_frequency_trigram_7.most_common(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "12. Use PMI (with 5 occurrence threshold) to compute top 10 results for the trigrams. Devise a method for computing the values, based on the results for bigrams."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "def pmi_tri(tri, total, global_frequency_list_words):\n",
    "    w1, w2, w3 = tri[0].split(\" \")\n",
    "    val_tri =tri[1]\n",
    "    val_w1 = global_frequency_list_words.__getitem__(w1)\n",
    "    vaw_w2 = global_frequency_list_words.__getitem__(w2)\n",
    "    vaw_w3 = global_frequency_list_words.__getitem__(w3)\n",
    "\n",
    "    return (w1, w2, w3, log((val_tri/total)/((val_w1/total)*(vaw_w2/total))*(vaw_w3/total)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "pmi_tri_tab = [pmi_tri(tri, total, global_frequency_list_words) for tri in global_frequency_trigram.most_common()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "[('adama', 'mickiewicza', 'w', 10.420414525160096),\n ('chrześcijan', 'baptystów', 'w', 10.112113165505578),\n ('hugona', 'kołłątaja', 'w', 9.909588901394104),\n ('tadeusza', 'kotarbińskiego', 'w', 9.909588901394104),\n ('wyznaniowa', 'żydowska', 'w', 9.791805865737722),\n ('michała', 'oczapowskiego', 'w', 9.727267344600149),\n ('lambrekiny', 'okienne', 'i', 9.461754795257422),\n ('przymusowo', 'zatrudnianym', 'w', 9.321802236491985),\n ('mistrzostw', 'europy', 'w', 9.28365047052761),\n ('starokatolickiego', 'mariawitów', 'w', 9.13948067969803)]"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi_tri_tab.sort(key=lambda x: x[3], reverse= True)\n",
    "pmi_tri_tab[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "pmi_tri__7 = [pmi_tri(tri, total_7, global_frequency_list_words_7) for tri in global_frequency_trigram_7.most_common() if tri[1]> 5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "[('adam:subst', 'mickiewicz:subst', 'w:prep', 10.42896038034885),\n ('teologiczno:ign', 'pastoralny:adj', 'w:prep', 10.274809700521592),\n ('curie:subst', 'skłodowska:subst', 'w:prep', 9.918134756582859),\n ('hugon:subst', 'kołłątaj:subst', 'w:prep', 9.918134756582859),\n ('tadeusz:subst', 'kotarbiński:subst', 'w:prep', 9.918134756582859),\n ('michał:subst', 'oczapowskiego:ign', 'w:prep', 9.735813199788904),\n ('leż:subst', 'leża:subst', 'w:prep', 9.202514720170855),\n ('linek:subst', 'link:subst', 'i:conj', 8.95951471311693),\n ('lambrekin:subst', 'okienny:adj', 'i:conj', 8.95131794591275),\n ('chłodnica:subst', 'odmulina:subst', 'i:conj', 8.923147068946054)]"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi_tri__7.sort(key=lambda x: x[3], reverse= True)\n",
    "pmi_tri__7[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "13. Create a table comparing the results for copora without and with tagging and lemmatization (separate table for bigrams and trigrams).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dt_bigram = pd.DataFrame(list(zip(\n",
    "    [item[0] for item in pmi_tab_filtered]\n",
    "    , [item[1] for item in pmi_tab_filtered]\n",
    "    , [item[2] for item in pmi_tab_filtered]\n",
    "    ,[item[0] for item in pmi_tab_filtered_7]\n",
    "    , [item[1] for item in pmi_tab_filtered_7]\n",
    "    , [item[2] for item in pmi_tab_filtered_7]\n",
    "    )), columns=['1 word', '2 word', 'scoore', '1 word', '2 word', 'scoore'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "           1 word           2 word     scoore             1 word  \\\n0           adama      mickiewicza  13.298941     postępować:fin   \n1        odczynów  poszczepiennych  13.298941          ląg:subst   \n2       diagności    laboratoryjni  13.298941         adam:subst   \n3           słomę           makową  13.298941       obrząd:subst   \n4      lambrekiny          okienne  13.144790         pielić:fin   \n...           ...              ...        ...                ...   \n64750           o                z  -5.516093  dyscyplinarny:adj   \n64751           w                i  -5.584700     towarowy:subst   \n64752           z                i  -5.690917            113:num   \n64753           o                w  -6.002940             za:qub   \n64754           w                w  -7.031063       szkoła:subst   \n\n                 2 word     scoore  \n0        postępywać:fin  13.450680  \n1             lęg:subst  13.450680  \n2      mickiewicz:subst  13.450680  \n3          obrzęd:subst  13.450680  \n4              pleć:fin  13.450680  \n...                 ...        ...  \n64750             5:num   0.662937  \n64751            i:conj   0.662933  \n64752             1:num   0.662820  \n64753   pracownik:subst   0.662699  \n64754          może:qub   0.662622  \n\n[64755 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1 word</th>\n      <th>2 word</th>\n      <th>scoore</th>\n      <th>1 word</th>\n      <th>2 word</th>\n      <th>scoore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>adama</td>\n      <td>mickiewicza</td>\n      <td>13.298941</td>\n      <td>postępować:fin</td>\n      <td>postępywać:fin</td>\n      <td>13.450680</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>odczynów</td>\n      <td>poszczepiennych</td>\n      <td>13.298941</td>\n      <td>ląg:subst</td>\n      <td>lęg:subst</td>\n      <td>13.450680</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>diagności</td>\n      <td>laboratoryjni</td>\n      <td>13.298941</td>\n      <td>adam:subst</td>\n      <td>mickiewicz:subst</td>\n      <td>13.450680</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>słomę</td>\n      <td>makową</td>\n      <td>13.298941</td>\n      <td>obrząd:subst</td>\n      <td>obrzęd:subst</td>\n      <td>13.450680</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lambrekiny</td>\n      <td>okienne</td>\n      <td>13.144790</td>\n      <td>pielić:fin</td>\n      <td>pleć:fin</td>\n      <td>13.450680</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>64750</th>\n      <td>o</td>\n      <td>z</td>\n      <td>-5.516093</td>\n      <td>dyscyplinarny:adj</td>\n      <td>5:num</td>\n      <td>0.662937</td>\n    </tr>\n    <tr>\n      <th>64751</th>\n      <td>w</td>\n      <td>i</td>\n      <td>-5.584700</td>\n      <td>towarowy:subst</td>\n      <td>i:conj</td>\n      <td>0.662933</td>\n    </tr>\n    <tr>\n      <th>64752</th>\n      <td>z</td>\n      <td>i</td>\n      <td>-5.690917</td>\n      <td>113:num</td>\n      <td>1:num</td>\n      <td>0.662820</td>\n    </tr>\n    <tr>\n      <th>64753</th>\n      <td>o</td>\n      <td>w</td>\n      <td>-6.002940</td>\n      <td>za:qub</td>\n      <td>pracownik:subst</td>\n      <td>0.662699</td>\n    </tr>\n    <tr>\n      <th>64754</th>\n      <td>w</td>\n      <td>w</td>\n      <td>-7.031063</td>\n      <td>szkoła:subst</td>\n      <td>może:qub</td>\n      <td>0.662622</td>\n    </tr>\n  </tbody>\n</table>\n<p>64755 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_bigram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "dt_trigram = pd.DataFrame(list(zip(\n",
    "    [item[0] for item in pmi_tri_tab]\n",
    "    , [item[1] for item in pmi_tri_tab]\n",
    "    , [item[2] for item in pmi_tri_tab]\n",
    "    , [item[3] for item in pmi_tri_tab]\n",
    "    ,[item[0] for item in pmi_tri__7]\n",
    "    , [item[1] for item in pmi_tri__7]\n",
    "    , [item[2] for item in pmi_tri__7]\n",
    "    , [item[3] for item in pmi_tri__7]\n",
    "    )), columns=['1 word', '2 word', '3 word', 'scoore', '1 word', '2 word', '3 word', 'scoore'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "            1 word          2 word              3 word     scoore  \\\n0            adama     mickiewicza                   w  10.420415   \n1      chrześcijan       baptystów                   w  10.112113   \n2           hugona       kołłątaja                   w   9.909589   \n3         tadeusza  kotarbińskiego                   w   9.909589   \n4       wyznaniowa        żydowska                   w   9.791806   \n...            ...             ...                 ...        ...   \n44875          się               w             trudnej -17.870916   \n44876          się               w     skonsolidowanym -17.896233   \n44877            w         których         występowało -17.981164   \n44878          się               w  niebezpieczeństwie -18.109807   \n44879          lub               w           arkuszach -18.349094   \n\n                1 word             2 word         3 word     scoore  \n0           adam:subst   mickiewicz:subst         w:prep  10.428960  \n1      teologiczno:ign     pastoralny:adj         w:prep  10.274810  \n2          curie:subst   skłodowska:subst         w:prep   9.918135  \n3          hugon:subst     kołłątaj:subst         w:prep   9.918135  \n4        tadeusz:subst  kotarbiński:subst         w:prep   9.918135  \n...                ...                ...            ...        ...  \n44875    żywność:subst         woda:subst      pitny:adj  -8.381750  \n44876        oraz:conj         wzór:subst  stosowany:adj  -8.381865  \n44877        albo:conj    jednostka:subst  policja:subst  -8.381919  \n44878   dopuszczać:fin            się:qub     czynny:adj  -8.382031  \n44879      jeżeli:comp        organ:subst      celny:adj  -8.382226  \n\n[44880 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1 word</th>\n      <th>2 word</th>\n      <th>3 word</th>\n      <th>scoore</th>\n      <th>1 word</th>\n      <th>2 word</th>\n      <th>3 word</th>\n      <th>scoore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>adama</td>\n      <td>mickiewicza</td>\n      <td>w</td>\n      <td>10.420415</td>\n      <td>adam:subst</td>\n      <td>mickiewicz:subst</td>\n      <td>w:prep</td>\n      <td>10.428960</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>chrześcijan</td>\n      <td>baptystów</td>\n      <td>w</td>\n      <td>10.112113</td>\n      <td>teologiczno:ign</td>\n      <td>pastoralny:adj</td>\n      <td>w:prep</td>\n      <td>10.274810</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hugona</td>\n      <td>kołłątaja</td>\n      <td>w</td>\n      <td>9.909589</td>\n      <td>curie:subst</td>\n      <td>skłodowska:subst</td>\n      <td>w:prep</td>\n      <td>9.918135</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tadeusza</td>\n      <td>kotarbińskiego</td>\n      <td>w</td>\n      <td>9.909589</td>\n      <td>hugon:subst</td>\n      <td>kołłątaj:subst</td>\n      <td>w:prep</td>\n      <td>9.918135</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>wyznaniowa</td>\n      <td>żydowska</td>\n      <td>w</td>\n      <td>9.791806</td>\n      <td>tadeusz:subst</td>\n      <td>kotarbiński:subst</td>\n      <td>w:prep</td>\n      <td>9.918135</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>44875</th>\n      <td>się</td>\n      <td>w</td>\n      <td>trudnej</td>\n      <td>-17.870916</td>\n      <td>żywność:subst</td>\n      <td>woda:subst</td>\n      <td>pitny:adj</td>\n      <td>-8.381750</td>\n    </tr>\n    <tr>\n      <th>44876</th>\n      <td>się</td>\n      <td>w</td>\n      <td>skonsolidowanym</td>\n      <td>-17.896233</td>\n      <td>oraz:conj</td>\n      <td>wzór:subst</td>\n      <td>stosowany:adj</td>\n      <td>-8.381865</td>\n    </tr>\n    <tr>\n      <th>44877</th>\n      <td>w</td>\n      <td>których</td>\n      <td>występowało</td>\n      <td>-17.981164</td>\n      <td>albo:conj</td>\n      <td>jednostka:subst</td>\n      <td>policja:subst</td>\n      <td>-8.381919</td>\n    </tr>\n    <tr>\n      <th>44878</th>\n      <td>się</td>\n      <td>w</td>\n      <td>niebezpieczeństwie</td>\n      <td>-18.109807</td>\n      <td>dopuszczać:fin</td>\n      <td>się:qub</td>\n      <td>czynny:adj</td>\n      <td>-8.382031</td>\n    </tr>\n    <tr>\n      <th>44879</th>\n      <td>lub</td>\n      <td>w</td>\n      <td>arkuszach</td>\n      <td>-18.349094</td>\n      <td>jeżeli:comp</td>\n      <td>organ:subst</td>\n      <td>celny:adj</td>\n      <td>-8.382226</td>\n    </tr>\n  </tbody>\n</table>\n<p>44880 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_trigram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "14. Answer the following questions:\n",
    "\n",
    "Why do we have to filter the bigrams, rather than the token sequence?\n",
    "\n",
    "Ponieważ powstawałyby błędne bigramy. Np ostanie słowo w zdaniu oraz pierwsze w kolejnym zostałyby połączone w bigram co tak normalnie nie ma miejsca. Ponadto w korpusie nad którym pracujemy często sa numery ustaw co również prowadziłoby do postawania błędnych bigramow\n",
    "\n",
    "Which method works better for the bigrams and which for the trigrams?\n",
    "\n",
    "Lepiej działa Pmi z filtrowaniem. Pozwala odfiltrować rzadkie wystąpienia które często mogą być literówkami. Zarówno działa to dla bigramow jak i trigramow. Jeśli chodzi o Clarin-PL lepiej działa dla bigramow ponieważ 3 wyraz to często spójnik.\n",
    "\n",
    "What types of expressions are discovered by the methods.\n",
    "\n",
    "Są okrywane wyrażenia typowe dla języka oraz typowe dla przerabianego korpusu. Mogą też być wykrywane błędy w tekście\n",
    "\n",
    "Can you devise a different type of filtering that would yield better results?\n",
    "\n",
    "Można pozbyć się spójników poprzez odfiltrowanie najkrótszych wyrazów. Występują często w jeżyku i maja małe znaczenie w większości przypadków"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
